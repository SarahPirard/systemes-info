
@article{al-ragehi_hyper-parameter_2022,
	title = {Hyper-Parameter Optimization of Semi-Supervised {GANs} Based-Sine Cosine Algorithm for Multimedia Datasets},
	abstract = {Generative Adversarial Networks ({GANs}) are neural networks that allow models to learn deep representations without requiring a large amount of training data. Semi-Supervised {GAN} Classifiers are a recent innovation in {GANs}, where {GANs} are used to classify generated images into real and fake and multiple classes, similar to a general multi-class classifier. However, {GANs} have a sophisticated design that can be challenging to train. This is because obtaining the proper set of parameters for all models-generator, discriminator, and classifier is complex. As a result, training a single {GAN} model for different datasets may not produce satisfactory results. Therefore, this study proposes an {SGAN} model (Semi-Supervised {GAN} Classifier). First, a baseline model was constructed. The model was then enhanced by leveraging the Sine-Cosine Algorithm and Synthetic Minority Oversampling Technique ({SMOTE}). {SMOTE} was used to address class imbalances in the dataset, while Sine Cosine Algorithm ({SCA}) was used to optimize the weights of the classifier models. The optimal set of hyperparameters (learning rate and batch size) were obtained using grid manual search. Four well-known benchmark datasets and a set of evaluation measures were used to validate the proposed model. The proposed method was then compared against existing models, and the results on each dataset were recorded and demonstrated the effectiveness of the proposed model. The proposed model successfully showed improved test accuracy scores of 1\%, 2\%, 15\%, and 5\% on benchmarking multimedia datasets; Modified National Institute of Standards and Technology ({MNIST}) digits, Fashion {MNIST}, Pneumonia Chest X-ray, and Facial Emotion Detection Dataset, respectively.},
	author = {Al-Ragehi, Anas and Abdulkadir, Said Jadid and Muneer, Amgad and Sadeq, Safwan and Al-Tashi, Qasem},
	date = {2022},
	langid = {english},
	file = {Al-Ragehi et al. - 2022 - Hyper-Parameter Optimization of Semi-Supervised GA.pdf:C\:\\Users\\pirar\\Zotero\\storage\\XIIFVT5V\\Al-Ragehi et al. - 2022 - Hyper-Parameter Optimization of Semi-Supervised GA.pdf:application/pdf},
}

@article{aggarwal_generative_2021,
	title = {Generative adversarial network: An overview of theory and applications},
	volume = {1},
	issn = {2667-0968},
	url = {https://www.sciencedirect.com/science/article/pii/S2667096820300045},
	doi = {10.1016/j.jjimei.2020.100004},
	shorttitle = {Generative adversarial network},
	abstract = {In recent times, image segmentation has been involving everywhere including disease diagnosis to autonomous vehicle driving. In computer vision, this image segmentation is one of the vital works and it is relatively complicated than other vision undertakings as it needs low-level spatial data. Especially, Deep Learning has impacted the field of segmentation incredibly and gave us today different successful models. The deep learning associated Generated Adversarial Networks ({GAN}) has presenting remarkable outcomes on image segmentation. In this study, the authors have presented a systematic review analysis on recent publications of {GAN} models and their applications. Three libraries such as Embase (Scopus), {WoS}, and {PubMed} have been considered for searching the relevant papers available in this area. Search outcomes have identified 2084 documents, after two-phase screening 52 potential records are included for final review. The following applications of {GAN} have been emerged: 3D object generation, medicine, pandemics, image processing, face detection, texture transfer, and traffic controlling. Before 2016, research in this field was limited and thereafter its practical usage came into existence worldwide. The present study also envisions the challenges associated with {GAN} and paves the path for future research in this realm.},
	pages = {100004},
	number = {1},
	journaltitle = {International Journal of Information Management Data Insights},
	shortjournal = {International Journal of Information Management Data Insights},
	author = {Aggarwal, Alankrita and Mittal, Mamta and Battineni, Gopi},
	urldate = {2022-12-15},
	date = {2021-04-01},
	langid = {english},
	keywords = {Big data, Deep learning, {GAN}, Image mining, Literature review, Neural networks},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\pirar\\Zotero\\storage\\7TS8VVM4\\Aggarwal et al. - 2021 - Generative adversarial network An overview of the.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\pirar\\Zotero\\storage\\TSMU83KC\\S2667096820300045.html:text/html},
}

@article{noauthor_generative_2022,
	title = {Generative Adversarial Networks: a systematic review and applications},
	abstract = {Since their introduction in 2014 Generative Adversarial Networks ({GANs}) have been employed successfully in many areas such as image processing, computer vision, medical imaging, video as well as other disciplines. A large number of review papers have been published, focusing on certain application areas and proposed methods. In this paper, we collected the most recent review papers, organized the collected information according to the application field and we presented the application areas, the {GAN} architectures that have been applied in each case and summarized the open issues in each area.},
	journaltitle = {{SHS} Web of Conferences},
	date = {2022},
	langid = {english},
	file = {2022 - Generative Adversarial Networks a systematic revi.pdf:C\:\\Users\\pirar\\Zotero\\storage\\3IIZAPEZ\\2022 - Generative Adversarial Networks a systematic revi.pdf:application/pdf},
}

@article{avanaki_quality_nodate,
	title = {Quality Enhancement of Gaming Content using Generative Adversarial Networks},
	abstract = {Recently, streaming of gameplay scenes has gained much attention, as evident with the rise of platforms such as Twitch.tv and Facebook Gaming. These streaming services have to deal with many challenges due to the low quality of source materials caused by client devices, network limitations such as bandwidth and packet loss, as well as low delay requirements. Spatial video artifact such as blockiness and blurriness as a result of as video compression or up-scaling algorithms can signiﬁcantly impact the Quality of Experience of end-users of passive gaming video streaming applications. In this paper, we investigate solutions to enhance the video quality of compressed gaming content. Recently, several super-resolution enhancement techniques using Generative Adversarial Network (e.g., {SRGAN}) have been proposed, which are shown to work with high accuracy on non-gaming content. Towards this end, we improved the {SRGAN} by adding a modiﬁed loss function as well as changing the generator network such as layer levels and skip connections to improve the ﬂow of information in the network, which is shown to improve the perceived quality signiﬁcantly. In addition, we present a performance evaluation of improved {SRGAN} for the enhancement of frame quality caused by compression and rescaling artifacts for gaming content encoded in multiple resolution-bitrate pairs.},
	author = {Avanaki, Nasim J and Zadtootaghaj, Saman and Barman, Nabajeet and Schmidt, Steven and Martini, Maria G and Moller, Sebastian},
	langid = {english},
	file = {Avanaki et al. - Quality Enhancement of Gaming Content using Genera.pdf:C\:\\Users\\pirar\\Zotero\\storage\\USHFZ834\\Avanaki et al. - Quality Enhancement of Gaming Content using Genera.pdf:application/pdf},
}

@article{guan_editable_2020,
	title = {Editable video creation based on embedded simulation engine and {GAN}},
	volume = {75},
	issn = {0141-9331},
	url = {https://www.sciencedirect.com/science/article/pii/S0141933120300831},
	doi = {10.1016/j.micpro.2020.103048},
	abstract = {With the progress of artificial intelligence, the embedded generation of images and videos by {AI} has become a hot topic. This technology is tried to be applied in real-time processing of monitors, cameras and smart phones. Using {GAN} embedder networks, some research attempts to transfer the style, action and content of one video to another target video. Unfortunately, this generation is often difficult to control. We have created an Engine-{GAN} (E-{GAN}) model process, which effectively combines engine method with embedder {GAN} content to create "real" videos that can be edited in real time. This makes the image and content generated by {AI} directly controlled. We have made progress in E-{GAN} architecture, E-{GAN} workflow, tag generation and entity stylization. We use cuckoo algorithm to optimize the migration target and improve the migration efficiency.},
	pages = {103048},
	journaltitle = {Microprocessors and Microsystems},
	shortjournal = {Microprocessors and Microsystems},
	author = {Guan, Zheng and Ding, Gangyi},
	urldate = {2022-12-15},
	date = {2020-06-01},
	langid = {english},
	keywords = {Embedded simulation engine, {GAN} Structure, Video generation},
	file = {ScienceDirect Snapshot:C\:\\Users\\pirar\\Zotero\\storage\\2AWQA3U3\\S0141933120300831.html:text/html},
}

@article{vidanaralage_ai-based_2022,
	title = {{AI}-based multidisciplinary framework to assess the impact of gamified video-based learning through schema and emotion analysis},
	volume = {3},
	issn = {2666-920X},
	url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000649},
	doi = {10.1016/j.caeai.2022.100109},
	abstract = {Background
As a natural and continual process, the initial learning stages encompass mastering and recalling basic facts. The process proves effective with the integration of new information with pre-existing knowledge characterised as schema to facilitate memory encoding. Additionally, emotions also have the ability to modulate human cognition in terms of learning and memory. The recent advent of gamification in e-learning, which has garnered much scholarly and industrial interest, necessitates a thorough examination between video-based learning and its subsequent implications on schema, emotions, and gamification.
Objectives
The current multidisciplinary research triangulated cognitive psychology, affective science, and education technology with artificial intelligence for evaluating digital learning pedagogy based on memory retrieval accuracy, response time, and emotional valence.
Design
This three-way (2 x 2 x 2) mixed factorial experiment design with repeated measures entailed 64 healthy young adult volunteers (n = 64) with 32 in the schema congruent group and 32 in the schema incongruent group. Additionally, 27 (42\%) of the volunteers were males, while 37 (58\%) were females with an age range between 20 and 39 years old (mean age 27.78 years, {SD} = 4.77 years).
Results
The findings demonstrate that the schema congruent group attained a statistically significant and higher retrieval accuracy (p {\textless} .001). The delayed recall response time was faster than its immediate recall counterpart (p {\textless} .001). Overall, the gamified learning mode depicted more positive emotions compared to non-gamified learning, although both groups primarily portrayed more negative emotions (p = .05).
Implications
The synthesis of current research aimed to recommend an {AI}-based multidisciplinary framework to assess the impact on adult learners in terms of schema and evaluate their emotions in experiencing gamified or non-gamified video materials as a learning medium. The implications expedited from this research offer valuable insights for diverse stakeholders engaged in the video-based learning ecosystem.},
	pages = {100109},
	journaltitle = {Computers and Education: Artificial Intelligence},
	shortjournal = {Computers and Education: Artificial Intelligence},
	author = {Vidanaralage, Anjana Junius and Dharmaratne, Anuja Thimali and Haque, Shamsul},
	urldate = {2022-12-15},
	date = {2022-01-01},
	langid = {english},
	keywords = {Artificial intelligence, Education technology, Emotion recognition, Gamification, Schema theory, Video-based learning},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\pirar\\Zotero\\storage\\L4Y6X3RJ\\Vidanaralage et al. - 2022 - AI-based multidisciplinary framework to assess the.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\pirar\\Zotero\\storage\\MTUGVQ8F\\S2666920X22000649.html:text/html},
}

@book{mao_generative_2021,
	location = {Singapore},
	title = {Generative Adversarial Networks for Image Generation},
	isbn = {978-981-336-047-1 978-981-336-048-8},
	url = {http://link.springer.com/10.1007/978-981-33-6048-8},
	publisher = {Springer},
	author = {Mao, Xudong and Li, Qing},
	urldate = {2022-12-17},
	date = {2021},
	langid = {english},
	doi = {10.1007/978-981-33-6048-8},
	keywords = {Adversarial Networks, Deep Learning, {GANs}, Generative Adversarial Networks, Generative Models, Image Generation, Image to Image Translation, Machine Learning, Neural Networks, Unsupervised Domain Adaptation},
	file = {Full Text PDF:C\:\\Users\\pirar\\Zotero\\storage\\BWZ9979Z\\Mao et Li - 2021 - Generative Adversarial Networks for Image Generati.pdf:application/pdf},
}

@incollection{mao_gans_2021,
	location = {Singapore},
	title = {{GANs} for Image Generation},
	isbn = {978-981-336-048-8},
	url = {https://doi.org/10.1007/978-981-33-6048-8_2},
	abstract = {Deep learning has proven to be hugely successful in computer vision and has even been applied to many real-world tasks, such as image classification (He et al. 2016), object detection (Ren et al. 2015), and segmentation (Long et al. 2015). Compared with these tasks in supervised learning, however, image generation, which belongs to unsupervised learning, may not achieve the desired performance. The target of image generation is to learn to draw pictures by means of some generative models, as shown in Fig. 2.1.},
	pages = {9--52},
	booktitle = {Generative Adversarial Networks for Image Generation},
	publisher = {Springer},
	author = {Mao, Xudong and Li, Qing},
	editor = {Mao, Xudong and Li, Qing},
	urldate = {2022-12-17},
	date = {2021},
	langid = {english},
	doi = {10.1007/978-981-33-6048-8_2},
	file = {Full Text PDF:C\:\\Users\\pirar\\Zotero\\storage\\3Q8ZC97R\\Mao et Li - 2021 - GANs for Image Generation.pdf:application/pdf},
}

@inproceedings{spick_realistic_2019,
	location = {London United Kingdom},
	title = {Realistic and Textured Terrain Generation using {GANs}},
	isbn = {978-1-4503-7003-5},
	url = {https://dl.acm.org/doi/10.1145/3359998.3369407},
	doi = {10.1145/3359998.3369407},
	eventtitle = {{CVMP} '19: European Conference on Visual Media Production},
	pages = {1--10},
	booktitle = {European Conference on Visual Media Production},
	publisher = {{ACM}},
	author = {spick, ryan rs and walker, james},
	urldate = {2022-12-17},
	date = {2019-12-17},
	langid = {english},
	file = {spick et walker - 2019 - Realistic and Textured Terrain Generation using GA.pdf:C\:\\Users\\pirar\\Zotero\\storage\\44VS24DA\\spick et walker - 2019 - Realistic and Textured Terrain Generation using GA.pdf:application/pdf},
}

@misc{jetchev_texture_2017,
	title = {Texture Synthesis with Spatial Generative Adversarial Networks},
	url = {http://arxiv.org/abs/1611.08207},
	doi = {10.48550/arXiv.1611.08207},
	abstract = {Generative adversarial networks ({GANs}) are a recent approach to train generative models of data, which have been shown to work particularly well on image data. In the current paper we introduce a new model for texture synthesis based on {GAN} learning. By extending the input noise distribution space from a single vector to a whole spatial tensor, we create an architecture with properties well suited to the task of texture synthesis, which we call spatial {GAN} ({SGAN}). To our knowledge, this is the first successful completely data-driven texture synthesis method based on {GANs}. Our method has the following features which make it a state of the art algorithm for texture synthesis: high image quality of the generated textures, very high scalability w.r.t. the output texture size, fast real-time forward generation, the ability to fuse multiple diverse source images in complex textures. To illustrate these capabilities we present multiple experiments with different classes of texture images and use cases. We also discuss some limitations of our method with respect to the types of texture images it can synthesize, and compare it to other neural techniques for texture generation.},
	number = {{arXiv}:1611.08207},
	publisher = {{arXiv}},
	author = {Jetchev, Nikolay and Bergmann, Urs and Vollgraf, Roland},
	urldate = {2022-12-17},
	date = {2017-09-08},
	eprinttype = {arxiv},
	eprint = {1611.08207 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\pirar\\Zotero\\storage\\RH8HWFZ4\\Jetchev et al. - 2017 - Texture Synthesis with Spatial Generative Adversar.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\pirar\\Zotero\\storage\\2Q9WE4CF\\1611.html:text/html},
}

@misc{volz_evolving_2018,
	title = {Evolving Mario Levels in the Latent Space of a Deep Convolutional Generative Adversarial Network},
	url = {http://arxiv.org/abs/1805.00728},
	abstract = {Generative Adversarial Networks ({GANs}) are a machine learning approach capable of generating novel example outputs across a space of provided training examples. Procedural Content Generation ({PCG}) of levels for video games could benefit from such models, especially for games where there is a pre-existing corpus of levels to emulate. This paper trains a {GAN} to generate levels for Super Mario Bros using a level from the Video Game Level Corpus. The approach successfully generates a variety of levels similar to one in the original corpus, but is further improved by application of the Covariance Matrix Adaptation Evolution Strategy ({CMA}-{ES}). Specifically, various fitness functions are used to discover levels within the latent space of the {GAN} that maximize desired properties. Simple static properties are optimized, such as a given distribution of tile types. Additionally, the champion A* agent from the 2009 Mario {AI} competition is used to assess whether a level is playable, and how many jumping actions are required to beat it. These fitness functions allow for the discovery of levels that exist within the space of examples designed by experts, and also guide the search towards levels that fulfill one or more specified objectives.},
	number = {{arXiv}:1805.00728},
	publisher = {{arXiv}},
	author = {Volz, Vanessa and Schrum, Jacob and Liu, Jialin and Lucas, Simon M. and Smith, Adam and Risi, Sebastian},
	urldate = {2022-12-17},
	date = {2018-05-02},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1805.00728 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	file = {Volz et al. - 2018 - Evolving Mario Levels in the Latent Space of a Dee.pdf:C\:\\Users\\pirar\\Zotero\\storage\\FTVJG46Z\\Volz et al. - 2018 - Evolving Mario Levels in the Latent Space of a Dee.pdf:application/pdf},
}

@misc{giacomello_doom_2018,
	title = {{DOOM} Level Generation using Generative Adversarial Networks},
	url = {http://arxiv.org/abs/1804.09154},
	abstract = {We applied Generative Adversarial Networks ({GANs}) to learn a model of {DOOM} levels from human-designed content. Initially, we analyzed the levels and extracted several topological features. Then, for each level, we extracted a set of images identifying the occupied area, the height map, the walls, and the position of game objects. We trained two {GANs}: one using plain level images, one using both the images and some of the features extracted during the preliminary analysis. We used the two networks to generate new levels and compared the results to assess whether the network trained using also the topological features could generate levels more similar to human-designed ones. Our results show that {GANs} can capture intrinsic structure of {DOOM} levels and appears to be a promising approach to level generation in ﬁrst person shooter games.},
	number = {{arXiv}:1804.09154},
	publisher = {{arXiv}},
	author = {Giacomello, Edoardo and Lanzi, Pier Luca and Loiacono, Daniele},
	urldate = {2022-12-17},
	date = {2018-04-24},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1804.09154 [cs, stat]},
	keywords = {Statistics - Machine Learning, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
	file = {Giacomello et al. - 2018 - DOOM Level Generation using Generative Adversarial.pdf:C\:\\Users\\pirar\\Zotero\\storage\\FRXC2FUZ\\Giacomello et al. - 2018 - DOOM Level Generation using Generative Adversarial.pdf:application/pdf},
}

@misc{torrado_bootstrapping_2019,
	title = {Bootstrapping Conditional {GANs} for Video Game Level Generation},
	url = {http://arxiv.org/abs/1910.01603},
	abstract = {Generative Adversarial Networks ({GANs}) have shown impressive results for image generation. However, {GANs} face challenges in generating contents with certain types of constraints, such as game levels. Speciﬁcally, it is difﬁcult to generate levels that have aesthetic appeal and are playable at the same time. Additionally, because training data usually is limited, it is challenging to generate unique levels with current {GANs}. In this paper, we propose a new {GAN} architecture named Conditional Embedding Self-Attention Generative Adversarial Network ({CESAGAN}) and a new bootstrapping training procedure. The {CESAGAN} is a modiﬁcation of the self-attention {GAN} that incorporates an embedding feature vector input to condition the training of the discriminator and generator. This allows the network to model non-local dependency between game objects, and to count objects. Additionally, to reduce the number of levels necessary to train the {GAN}, we propose a bootstrapping mechanism in which playable generated levels are added to the training set. The results demonstrate that the new approach does not only generate a larger number of levels that are playable but also generates fewer duplicate levels compared to a standard {GAN}.},
	number = {{arXiv}:1910.01603},
	publisher = {{arXiv}},
	author = {Torrado, Ruben Rodriguez and Khalifa, Ahmed and Green, Michael Cerny and Justesen, Niels and Risi, Sebastian and Togelius, Julian},
	urldate = {2022-12-17},
	date = {2019-10-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1910.01603 [cs]},
	keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Machine Learning},
	file = {Torrado et al. - 2019 - Bootstrapping Conditional GANs for Video Game Leve.pdf:C\:\\Users\\pirar\\Zotero\\storage\\RZM7VAAW\\Torrado et al. - 2019 - Bootstrapping Conditional GANs for Video Game Leve.pdf:application/pdf},
}

@misc{moghadam_game_2022,
	title = {Game of {GANs}: Game-Theoretical Models for Generative Adversarial Networks},
	url = {http://arxiv.org/abs/2106.06976},
	shorttitle = {Game of {GANs}},
	abstract = {Generative Adversarial Networks ({GANs}) have recently attracted considerable attention in the {AI} community due to its ability to generate high-quality data of signiﬁcant statistical resemblence to real data. Fundamentally, {GAN} is a game between two neural networks trained in an adversarial manner to reach a zero-sum Nash equilibrium proﬁle. Despite the improvement accomplished in {GANs} in the last few years, several issues remain to be solved. This paper reviews the literature on the game theoretic aspects of {GANs} and addresses how game theory models can address speciﬁc challenges of generative model and improve the {GAN}’s performance. We ﬁrst present some preliminaries, including the basic {GAN} model and some game theory background. We then present taxonomy to classify stateof-the-art solutions into three main categories: modiﬁed game models, modiﬁed architectures, and modiﬁed learning methods. The classiﬁcation is based on modiﬁcations made to the basic {GAN} model by proposed game-theoretic approaches in the literature. We then explore the objectives of each category and discuss recent works in each category. Finally, we discuss the remaining challenges in this ﬁeld and present future research directions.},
	number = {{arXiv}:2106.06976},
	publisher = {{arXiv}},
	author = {Moghadam, Monireh Mohebbi and Boroomand, Bahar and Jalali, Mohammad and Zareian, Arman and {DaeiJavad}, Alireza and Manshaei, Mohammad Hossein and Krunz, Marwan},
	urldate = {2022-12-17},
	date = {2022-01-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2106.06976 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computer Science and Game Theory},
	file = {Moghadam et al. - 2022 - Game of GANs Game-Theoretical Models for Generati.pdf:C\:\\Users\\pirar\\Zotero\\storage\\RILTGFIN\\Moghadam et al. - 2022 - Game of GANs Game-Theoretical Models for Generati.pdf:application/pdf},
}

@article{rajabi_dynamic_2020,
	title = {A dynamic balanced level generator for video games based on deep convolutional generative adversarial networks},
	url = {http://scientiairanica.sharif.edu/article_22082.html},
	doi = {10.24200/sci.2020.54747.3897},
	abstract = {In the gaming industry, creating well-balanced games is one of the major challenges developers are currently facing. Balance in games has di erent meanings depending on the game type. But, most existing de nitions are de ned from ow theory. In this research, Generative Adversarial Networks ({GANs}) have been used to automatically create balanced levels. In the proposed work, a level of a 2D platformer game is considered as a picture and is fed to the network. The levels are randomly created while adhering to a set of balance requirements. Those levels that can be solved with the help of an agent using reinforcement learning in the number of tries set by designers are given as input data to the network. Finally, the network automatically generates new balanced levels and then, the levels are checked to see if they have the game's minimum necessary requirements and also to check if they can be solved by the reinforcement learning agent. The best performing network is then selected for the level generation. In the series of performed evaluations, it is shown that after the training process, the proposed approach is capable of generating levels that are well-balanced with considerable accuracy.},
	pages = {1497--1514},
	journaltitle = {Scientia Iranica},
	author = {Rajabi, M and Ashtiani, M and Minaei-Bidgoli, B and Davoodi, O},
	date = {2020-11-16},
	langid = {english},
	file = {Rajabi et al. - 2021 - A dynamic balanced level generator for video games.pdf:C\:\\Users\\pirar\\Zotero\\storage\\5GW5VT66\\Rajabi et al. - 2021 - A dynamic balanced level generator for video games.pdf:application/pdf},
}

@inproceedings{kumaran_generating_2020,
	location = {Palo Alto, California},
	title = {Generating Game Levels for Multiple Distinct Games with a Common Latent Space},
	isbn = {978-1-57735-849-7},
	abstract = {Generative adversarial networks ({GANs}) are showing significant promise for procedural content generation ({PCG}) of game levels. {GAN} models generate game levels by mapping a low dimensional latent space to game levels in the game space. An intriguing challenge in {GAN}-based {PCG} is enabling {GANs} to produce game levels for multiple distinct games with similar gameplay characteristics using a common underlying low-dimensional representation. In this paper, we present a method for training a novel {GAN}-based {PCG} architecture that generates levels in multiple distinct games, starting from a common gameplay action sequence. We evaluate the solvability of the generated games using an automated playing agent and show how the generated game levels are separate representations of the same gameplay by quantifying the similarity between the solution action sequences for the game levels. By probing the common latent space, we show how our approach provides control over the levels generated in distinct games for the presence of desired gameplay patterns in the generated game levels. Results also demonstrate that the {GAN}-based {PCG} approach creates novel game levels in multiple distinct games, as indicated by the distance between the action sequences required to solve the game levels.},
	eventtitle = {Sixteenth {AAAI} Conference on Artificial Intelligence and Interactive Digital Entertainment},
	pages = {360p},
	booktitle = {Proceedings of the Sixteenth {AAAI} Conference on Artificial Intelligence and Interactive Digital Entertainment ({AIIDE}-20)},
	publisher = {{AAAI} Press},
	author = {Kumaran, Vikram and Mott, Bradford W and Lester, James C},
	date = {2020-10-19},
	langid = {english},
	file = {Kumaran et al. - Generating Game Levels for Multiple Distinct Games.pdf:C\:\\Users\\pirar\\Zotero\\storage\\ICDUQAVH\\Kumaran et al. - Generating Game Levels for Multiple Distinct Games.pdf:application/pdf},
}

@inproceedings{acornley_using_2021,
	location = {Montréal {QC} Canada},
	title = {Using Generative Adversarial Networks to Create Graphical User Interfaces for Video Games},
	isbn = {978-1-4503-8481-0},
	url = {https://dl.acm.org/doi/10.1145/3462244.3481273},
	doi = {10.1145/3462244.3481273},
	abstract = {Designing and creating a Graphical User Interface ({GUI}) is a difficult and slow process. It requires a number of professions to all contribute to its development and it can be heavily detrimental to a product if implemented poorly. This research aims to investigate a method of using Generative Adversarial Networks ({GANs}) to generate new and usable designs for {GUIs}. {GANs} are a relatively new architecture for adversarial learning and have been used to good effect in replicating instances of a real dataset. The primary aim is to develop a {GAN} that is capable of processing a collection of existing {GUIs} and learn how to replicate these to allow for creation of further designs. These {GUI} designs need to be formatted in a manner that enables modification, allowing for them to be used by a development team to enhance their production process. Completed work demonstrates numerous approaches at using {GANs} to create text files that contain the component elements of a {GUI}. Their results and the release of a similar research paper ({GUIGAN}) has led to a new approach focusing on more abstract data representation, with a quality control system for ensuring the output data is properly formatted. It is hypothesised that the approach will develop a model capable of creating new, editable {GUI} designs.},
	eventtitle = {{ICMI} '21: {INTERNATIONAL} {CONFERENCE} {ON} {MULTIMODAL} {INTERACTION}},
	pages = {802--806},
	booktitle = {Proceedings of the 2021 International Conference on Multimodal Interaction},
	publisher = {{ACM}},
	author = {Acornley, Christopher},
	urldate = {2022-12-17},
	date = {2021-10-18},
	langid = {english},
	file = {Acornley - 2021 - Using Generative Adversarial Networks to Create Gr.pdf:C\:\\Users\\pirar\\Zotero\\storage\\PUQ8MHST\\Acornley - 2021 - Using Generative Adversarial Networks to Create Gr.pdf:application/pdf},
}

@article{porkodi_generic_2022,
	title = {Generic image application using {GANs} (Generative Adversarial Networks): A Review},
	issn = {1868-6478, 1868-6486},
	url = {https://link.springer.com/10.1007/s12530-022-09464-y},
	doi = {10.1007/s12530-022-09464-y},
	shorttitle = {Generic image application using {GANs} (Generative Adversarial Networks)},
	abstract = {The generative adversarial network ({GAN}), which has received considerable notice for its outstanding data generating abilities, is one of the most intriguing fields of artificial intelligence study. Large volumes of data are required to develop generalizable deep learning models. {GANs} are a highly strong class of networks capable of producing believable new pictures from unlabeled source prints and labeled medical imaging data is scarce and costly to produce. Despite {GAN}’s remarkable outcomes, steady training remains a challenge. The goal of this study is to perform a complete evaluation of the {GAN}-related literature and to present a succinct summary of existing knowledge on {GAN}, including the theory following it, its intended purpose, potential base model alterations, and latest breakthroughs in the area. This article will aid you in gaining a comprehensive grasp of {GAN} and provide an overview of {GAN} and its many model types, as well as common implementations, measurement parameter suggestions, and {GAN} applications in image processing. It will also go over the several applications of {GANs} in image processing, as well as their benefits and limitations, as well as its prospective reach.},
	journaltitle = {Evolving Systems},
	shortjournal = {Evolving Systems},
	author = {Porkodi, S. P. and Sarada, V. and Maik, Vivek and Gurushankar, K.},
	urldate = {2022-12-17},
	date = {2022-09-30},
	langid = {english},
	file = {Porkodi et al. - 2022 - Generic image application using GANs (Generative A.pdf:C\:\\Users\\pirar\\Zotero\\storage\\EPMDKIST\\Porkodi et al. - 2022 - Generic image application using GANs (Generative A.pdf:application/pdf},
}

@article{mishra_fregan_nodate,
	title = {{FREGAN}: Frame Rate Enhancement in Videos using Generative Adversarial Networks},
	abstract = {A digital video is a collection of individual frames, while streaming the video the scene utilized the time slice for each frame. High refresh rate and high frame rate is the demand of all high technology applications. The action tracking in videos becomes easier and motion becomes smoother in gaming applications due to the high refresh rate. It provides a faster response because of less time in between each frame that is displayed on the screen. {FREGAN} (Frame Rate Enhancement Generative Adversarial Network) model has been proposed, which predicts future frames of a video sequence based on a sequence of past frames. In this paper, we investigated the {GAN} model and proposed {FREGAN} for the enhancement of frame rate in videos. We have utilized Huber loss as a loss function in the proposed {FREGAN}. It provided excellent results in super-resolution and we have tried to reciprocate that performance in the application of frame rate enhancement. We have validated the effectiveness of the proposed model on the standard datasets ({UCF}101 and {RFree}500). The experimental outcomes illustrate that the proposed model has a Peak signal-to-noise ratio ({PSNR}) of 34.94 and a Structural Similarity Index ({SSIM}) of 0.95.},
	author = {Mishra, Rishik and Gupta, Neeraj and Shukla, Nitya},
	langid = {english},
	file = {Mishra et al. - FREGAN Frame Rate Enhancement in Videos using Gen.pdf:C\:\\Users\\pirar\\Zotero\\storage\\9PMAAN7D\\Mishra et al. - FREGAN Frame Rate Enhancement in Videos using Gen.pdf:application/pdf},
}

@incollection{brooks_deep_2018,
	location = {Cham},
	title = {Deep Convolutional Generative Adversarial Network for Procedural 3D Landscape Generation Based on {DEM}},
	volume = {229},
	isbn = {978-3-319-76907-3 978-3-319-76908-0},
	url = {http://link.springer.com/10.1007/978-3-319-76908-0_9},
	abstract = {This paper proposes a novel framework for improving procedural generation of 3D landscapes using machine learning. We utilized a Deep Convolutional Generative Adversarial Network ({DC}-{GAN}) to generate heightmaps. The network was trained on a dataset consisting of Digital Elevation Maps ({DEM}) of the alps. During map generation, the batch size and learning rate were optimized for the most efﬁcient and satisfying map production. The diversity of the ﬁnal output was tested against Perlin noise using Mean Square Error [1] and Structure Similarity Index [2]. Perlin noise is especially interesting as it has been used to generate game maps in previous productions [3, 4]. The diversity test showed the generated maps had a signiﬁcantly greater diversity than the Perlin noise maps. Afterwards the heightmaps was converted to 3D maps in Unity3D. The 3D maps’ perceived realism and videogame usability was pilot tested, showing a promising future for {DC}-{GAN} generated 3D landscapes.},
	pages = {85--94},
	booktitle = {Interactivity, Game Creation, Design, Learning, and Innovation},
	publisher = {Springer International Publishing},
	author = {Wulff-Jensen, Andreas and Rant, Niclas Nerup and Møller, Tobias Nordvig and Billeskov, Jonas Aksel},
	editor = {Brooks, Anthony L. and Brooks, Eva and Vidakis, Nikolas},
	urldate = {2022-12-17},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-319-76908-0_9},
	note = {Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
	file = {Wulff-Jensen et al. - 2018 - Deep Convolutional Generative Adversarial Network .pdf:C\:\\Users\\pirar\\Zotero\\storage\\KYW5YY3I\\Wulff-Jensen et al. - 2018 - Deep Convolutional Generative Adversarial Network .pdf:application/pdf},
}
